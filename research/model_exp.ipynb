{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rahul\\\\Downloads\\\\sign_language_conversion\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rahul\\\\Downloads\\\\sign_language_conversion'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_data = test_generator.flow_from_directory(\n",
    "    'artifacts\\\\data_ingestion\\\\dataset\\\\Test',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\Downloads\\sign_language_conversion\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9624 - loss: 0.1081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12832129001617432, 0.9553571343421936]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in the dataset: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Nothing', 'O', 'P', 'Q', 'R', 'S', 'Space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_classes_from_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Traverses the dataset directory and creates an array of class names.\n",
    "    \n",
    "    Args:\n",
    "    - dataset_path (str): Path to the dataset directory.\n",
    "    \n",
    "    Returns:\n",
    "    - class_names (list): List of class names.\n",
    "    \"\"\"\n",
    "    # Check if the dataset path exists\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise ValueError(f\"Dataset path '{dataset_path}' does not exist.\")\n",
    "    \n",
    "    # List all subdirectories in the dataset path\n",
    "    class_names = []\n",
    "    for item in os.listdir(dataset_path):\n",
    "        item_path = os.path.join(dataset_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            class_names.append(item)\n",
    "    \n",
    "    return class_names\n",
    "\n",
    "# Example usage\n",
    "dataset_path = 'artifacts\\data_ingestion\\dataset\\Train'\n",
    "class_names = get_classes_from_dataset(dataset_path)\n",
    "print(\"Classes in the dataset:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_image_class(model, img_path, class_names):\n",
    "    \"\"\"\n",
    "    Predicts the class of an image using the provided model.\n",
    "    \n",
    "    Args:\n",
    "    - model: The pre-trained model.\n",
    "    - img_path (str): Path to the image to be predicted.\n",
    "    - class_names (list, optional): List of class names corresponding to the model's output. Only needed if not using ImageNet classes.\n",
    "    \n",
    "    Returns:\n",
    "    - predicted_class (str): The predicted class name.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Predict the class\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    if class_names:\n",
    "        # If custom class names are provided, use them\n",
    "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "        predicted_class = class_names[predicted_class_index]\n",
    "    else:\n",
    "        # Use ImageNet class names\n",
    "        decoded_predictions = decode_predictions(predictions, top=1)\n",
    "        predicted_class = decoded_predictions[0][0][1]  # Get the class name\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "image_path = \"artifacts\\\\data_ingestion\\\\dataset\\\\Train\\\\L\\\\7.jpg\"\n",
    "\n",
    "predict_image_class(model,image_path,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.1, 0.4),\n",
    "    zoom_range=0.4,\n",
    "    channel_shift_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_data = train_generator.flow_from_directory(\n",
    "    '/teamspace/studios/this_studio/dataset/Train',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_data = test_generator.flow_from_directory(\n",
    "    '/teamspace/studios/this_studio/dataset/Test',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "pretrained_model = VGG16(include_top=False, input_shape=input_shape, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "block_output = pretrained_model.get_layer('block5_pool').output\n",
    "\n",
    "x = Flatten()(block_output)\n",
    "\n",
    "x = Dense(512, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(216, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "output = Dense(28, activation='softmax', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.load_weights('checkpoints/weights.008-0.9911.weights.h5')\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
