{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf.symbol_database')\n",
    "\n",
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.5.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: X has 42 features, but RandomForestClassifier is expecting 84 features as input.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model from the pickle file\n",
    "model_dict = pickle.load(open('D:\\\\sign_language_conversion\\\\beta_code\\\\model1.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# Initialize the VideoCapture object for the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe hands solution\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Dictionary to map prediction labels to characters\n",
    "labels_dict = {0: 'A', 1: 'B', 2: 'C',2: 'D',3: 'E',4: 'F',5: 'G',6: 'H',7: 'I',8: 'J'}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data_aux = []\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        H, W, _ = frame.shape\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(frame_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,  # image to draw\n",
    "                    hand_landmarks,  # model output\n",
    "                    mp_hands.HAND_CONNECTIONS,  # hand connections\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            x1 = int(min(x_) * W) - 10\n",
    "            y1 = int(min(y_) * H) - 10\n",
    "\n",
    "            x2 = int(max(x_) * W) - 10\n",
    "            y2 = int(max(y_) * H) - 10\n",
    "\n",
    "            prediction = model.predict([np.asarray(data_aux)])\n",
    "\n",
    "            predicted_character = labels_dict[int(prediction[0])]\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "            cv2.putText(frame, predicted_character, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                        cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Release the camera and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # Add a small delay to ensure all windows are closed\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.5.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n",
      "Warning: Incorrect number of features extracted.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model from the pickle file\n",
    "model_dict = pickle.load(open('D:\\\\sign_language_conversion\\\\beta_code\\\\model1.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# Initialize the VideoCapture object for the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe hands solution\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "def extract_features(hand_landmarks):\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    data_aux = []\n",
    "\n",
    "    for landmark in hand_landmarks.landmark:\n",
    "        x_.append(landmark.x)\n",
    "        y_.append(landmark.y)\n",
    "\n",
    "    if len(x_) == 21 and len(y_) == 21:  # There should be 21 landmarks\n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            data_aux.append(landmark.x - min(x_))\n",
    "            data_aux.append(landmark.y - min(y_))\n",
    "    return data_aux\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        H, W, _ = frame.shape\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,  # image to draw\n",
    "                    hand_landmarks,  # model output\n",
    "                    mp_hands.HAND_CONNECTIONS,  # hand connections\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                data_aux = extract_features(hand_landmarks)\n",
    "\n",
    "                if len(data_aux) == 84:  # Ensure the feature vector has the correct number of features\n",
    "                    x1 = int(min([lm.x for lm in hand_landmarks.landmark]) * W) - 10\n",
    "                    y1 = int(min([lm.y for lm in hand_landmarks.landmark]) * H) - 10\n",
    "                    x2 = int(max([lm.x for lm in hand_landmarks.landmark]) * W) - 10\n",
    "                    y2 = int(max([lm.y for lm in hand_landmarks.landmark]) * H) - 10\n",
    "\n",
    "                    prediction = model.predict([np.asarray(data_aux)])\n",
    "                    predicted_class = int(prediction[0])\n",
    "\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "                    cv2.putText(frame, str(predicted_class), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                                cv2.LINE_AA)\n",
    "                else:\n",
    "                    print(\"Warning: Incorrect number of features extracted.\")\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Release the camera and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # Add a small delay to ensure all windows are closed\n",
    "    cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
